{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403a52272-dot/nlp/blob/main/2403A52272_LAB_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQGvpvohO4BJ",
        "outputId": "b60fcce1-7455-4b89-9298-4d0123493325"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Counts:\n",
            "the: 8\n",
            "to: 5\n",
            "for: 3\n",
            "you: 2\n",
            "rain: 1\n",
            "poured: 1\n",
            "softly: 1\n",
            "as: 1\n",
            "city: 1\n",
            "lights: 1\n",
            "flickered: 1\n",
            "in: 1\n",
            "distance.: 1\n",
            "i: 1\n",
            "am: 1\n",
            "writing: 1\n",
            "confirm: 1\n",
            "our: 1\n",
            "appointment: 1\n",
            "scheduled: 1\n",
            "tomorrow: 1\n",
            "at: 1\n",
            "noon.: 1\n",
            "photosynthesis: 1\n",
            "allows: 1\n",
            "plants: 1\n",
            "convert: 1\n",
            "sunlight: 1\n",
            "into: 1\n",
            "energy.: 1\n",
            "recycling: 1\n",
            "daily: 1\n",
            "helps: 1\n",
            "protect: 1\n",
            "environment: 1\n",
            "future: 1\n",
            "generations.: 1\n",
            "are: 1\n",
            "coming: 1\n",
            "with: 1\n",
            "us?”: 1\n",
            "she: 1\n",
            "asked: 1\n",
            "quietly.: 1\n",
            "aroma: 1\n",
            "of: 1\n",
            "fresh: 1\n",
            "bread: 1\n",
            "filled: 1\n",
            "warm: 1\n",
            "kitchen.: 1\n",
            "press: 1\n",
            "and: 1\n",
            "hold: 1\n",
            "button: 1\n",
            "ten: 1\n",
            "seconds: 1\n",
            "restart: 1\n",
            "device.: 1\n",
            "success: 1\n",
            "comes: 1\n",
            "from: 1\n",
            "small: 1\n",
            "efforts: 1\n",
            "repeated: 1\n",
            "consistently: 1\n",
            "over: 1\n",
            "time.: 1\n",
            "officials: 1\n",
            "announced: 1\n",
            "new: 1\n",
            "policies: 1\n",
            "improve: 1\n",
            "public: 1\n",
            "transportation.: 1\n",
            "every: 1\n",
            "challenge: 1\n",
            "face: 1\n",
            "is: 1\n",
            "an: 1\n",
            "opportunity: 1\n",
            "grow.: 1\n",
            "Vocabulary Size= 82\n"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "D1:\"The rain poured softly as the city lights flickered in the distance.\"\n",
        "\n",
        "D2:\"I am writing to confirm our appointment scheduled for tomorrow at noon.\"\n",
        "\n",
        "D3:\"Photosynthesis allows plants to convert sunlight into energy.\"\n",
        "\n",
        "D4:\"Recycling daily helps protect the environment for future generations.\"\n",
        "\n",
        "D5:\"Are you coming with us?” she asked quietly.\"\n",
        "\n",
        "D6:\"The aroma of fresh bread filled the warm kitchen.\"\n",
        "\n",
        "D7:\"Press and hold the button for ten seconds to restart the device.\"\n",
        "\n",
        "D8:\"Success comes from small efforts repeated consistently over time.\"\n",
        "\n",
        "D9:\"Officials announced new policies to improve public transportation.\"\n",
        "\n",
        "D10:\"Every challenge you face is an opportunity to grow.\"\n",
        "\n",
        "D1content=\"The rain poured softly as the city lights flickered in the distance.\"\n",
        "\n",
        "D2content=\"I am writing to confirm our appointment scheduled for tomorrow at noon.\"\n",
        "\n",
        "D3content=\"Photosynthesis allows plants to convert sunlight into energy.\"\n",
        "\n",
        "D4content=\"Recycling daily helps protect the environment for future generations.\"\n",
        "\n",
        "D5content=\"Are you coming with us?” she asked quietly.\"\n",
        "\n",
        "D6content=\"The aroma of fresh bread filled the warm kitchen.\"\n",
        "\n",
        "D7content=\"Press and hold the button for ten seconds to restart the device.\"\n",
        "\n",
        "D8content=\"Success comes from small efforts repeated consistently over time.\"\n",
        "\n",
        "D9content=\"Officials announced new policies to improve public transportation.\"\n",
        "\n",
        "D10content=\"Every challenge you face is an opportunity to grow.\"\n",
        "combined_text = f\"{D1content} {D2content} {D3content} {D4content} {D5content} {D6content} {D7content} {D8content} {D9content} {D10content}\"\n",
        "\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "unigram_counts = collections.Counter(words)\n",
        "\n",
        "print(\"Unigram Counts:\")\n",
        "for word, count in unigram_counts.most_common():\n",
        "    print(f\"{word}: {count}\")\n",
        "V=len(unigram_counts)\n",
        "print(\"Vocabulary Size=\",V)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV8Uj-ZjTG5p"
      },
      "source": [
        "Bi-Gram Counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "364-2oQJTR9B",
        "outputId": "58495a95-2ccc-4183-bbd2-282d2fdf5701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bigram Counts:\n",
            "the rain: 1\n",
            "rain poured: 1\n",
            "poured softly: 1\n",
            "softly as: 1\n",
            "as the: 1\n",
            "the city: 1\n",
            "city lights: 1\n",
            "lights flickered: 1\n",
            "flickered in: 1\n",
            "in the: 1\n",
            "the distance.: 1\n",
            "distance. i: 1\n",
            "i am: 1\n",
            "am writing: 1\n",
            "writing to: 1\n",
            "to confirm: 1\n",
            "confirm our: 1\n",
            "our appointment: 1\n",
            "appointment scheduled: 1\n",
            "scheduled for: 1\n",
            "for tomorrow: 1\n",
            "tomorrow at: 1\n",
            "at noon.: 1\n",
            "noon. photosynthesis: 1\n",
            "photosynthesis allows: 1\n",
            "allows plants: 1\n",
            "plants to: 1\n",
            "to convert: 1\n",
            "convert sunlight: 1\n",
            "sunlight into: 1\n",
            "into energy.: 1\n",
            "energy. recycling: 1\n",
            "recycling daily: 1\n",
            "daily helps: 1\n",
            "helps protect: 1\n",
            "protect the: 1\n",
            "the environment: 1\n",
            "environment for: 1\n",
            "for future: 1\n",
            "future generations.: 1\n",
            "generations. are: 1\n",
            "are you: 1\n",
            "you coming: 1\n",
            "coming with: 1\n",
            "with us?”: 1\n",
            "us?” she: 1\n",
            "she asked: 1\n",
            "asked quietly.: 1\n",
            "quietly. the: 1\n",
            "the aroma: 1\n",
            "aroma of: 1\n",
            "of fresh: 1\n",
            "fresh bread: 1\n",
            "bread filled: 1\n",
            "filled the: 1\n",
            "the warm: 1\n",
            "warm kitchen.: 1\n",
            "kitchen. press: 1\n",
            "press and: 1\n",
            "and hold: 1\n",
            "hold the: 1\n",
            "the button: 1\n",
            "button for: 1\n",
            "for ten: 1\n",
            "ten seconds: 1\n",
            "seconds to: 1\n",
            "to restart: 1\n",
            "restart the: 1\n",
            "the device.: 1\n",
            "device. success: 1\n",
            "success comes: 1\n",
            "comes from: 1\n",
            "from small: 1\n",
            "small efforts: 1\n",
            "efforts repeated: 1\n",
            "repeated consistently: 1\n",
            "consistently over: 1\n",
            "over time.: 1\n",
            "time. officials: 1\n",
            "officials announced: 1\n",
            "announced new: 1\n",
            "new policies: 1\n",
            "policies to: 1\n",
            "to improve: 1\n",
            "improve public: 1\n",
            "public transportation.: 1\n",
            "transportation. every: 1\n",
            "every challenge: 1\n",
            "challenge you: 1\n",
            "you face: 1\n",
            "face is: 1\n",
            "is an: 1\n",
            "an opportunity: 1\n",
            "opportunity to: 1\n",
            "to grow.: 1\n"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "\n",
        "\n",
        "combined_text = f\"{D1content} {D2content} {D3content} {D4content} {D5content} {D6content} {D7content} {D8content} {D9content} {D10content}\"\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "bigrams = []\n",
        "for i in range(len(words) - 1):\n",
        "    bigrams.append((words[i], words[i+1]))\n",
        "\n",
        "bigram_counts = collections.Counter(bigrams);\n",
        "\n",
        "print(\"\\nBigram Counts:\")\n",
        "for bigram, count in bigram_counts.most_common():\n",
        "    print(f\"{bigram[0]} {bigram[1]}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emjrc-h6WMcx"
      },
      "source": [
        "Tri-Gram Counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbugOJ7nWNTj",
        "outputId": "d5d4889c-2b16-4c0d-d786-51337f604128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trigrams Counts:\n",
            "the rain poured: 1\n",
            "rain poured softly: 1\n",
            "poured softly as: 1\n",
            "softly as the: 1\n",
            "as the city: 1\n",
            "the city lights: 1\n",
            "city lights flickered: 1\n",
            "lights flickered in: 1\n",
            "flickered in the: 1\n",
            "in the distance.: 1\n",
            "the distance. i: 1\n",
            "distance. i am: 1\n",
            "i am writing: 1\n",
            "am writing to: 1\n",
            "writing to confirm: 1\n",
            "to confirm our: 1\n",
            "confirm our appointment: 1\n",
            "our appointment scheduled: 1\n",
            "appointment scheduled for: 1\n",
            "scheduled for tomorrow: 1\n",
            "for tomorrow at: 1\n",
            "tomorrow at noon.: 1\n",
            "at noon. photosynthesis: 1\n",
            "noon. photosynthesis allows: 1\n",
            "photosynthesis allows plants: 1\n",
            "allows plants to: 1\n",
            "plants to convert: 1\n",
            "to convert sunlight: 1\n",
            "convert sunlight into: 1\n",
            "sunlight into energy.: 1\n",
            "into energy. recycling: 1\n",
            "energy. recycling daily: 1\n",
            "recycling daily helps: 1\n",
            "daily helps protect: 1\n",
            "helps protect the: 1\n",
            "protect the environment: 1\n",
            "the environment for: 1\n",
            "environment for future: 1\n",
            "for future generations.: 1\n",
            "future generations. are: 1\n",
            "generations. are you: 1\n",
            "are you coming: 1\n",
            "you coming with: 1\n",
            "coming with us?”: 1\n",
            "with us?” she: 1\n",
            "us?” she asked: 1\n",
            "she asked quietly.: 1\n",
            "asked quietly. the: 1\n",
            "quietly. the aroma: 1\n",
            "the aroma of: 1\n",
            "aroma of fresh: 1\n",
            "of fresh bread: 1\n",
            "fresh bread filled: 1\n",
            "bread filled the: 1\n",
            "filled the warm: 1\n",
            "the warm kitchen.: 1\n",
            "warm kitchen. press: 1\n",
            "kitchen. press and: 1\n",
            "press and hold: 1\n",
            "and hold the: 1\n",
            "hold the button: 1\n",
            "the button for: 1\n",
            "button for ten: 1\n",
            "for ten seconds: 1\n",
            "ten seconds to: 1\n",
            "seconds to restart: 1\n",
            "to restart the: 1\n",
            "restart the device.: 1\n",
            "the device. success: 1\n",
            "device. success comes: 1\n",
            "success comes from: 1\n",
            "comes from small: 1\n",
            "from small efforts: 1\n",
            "small efforts repeated: 1\n",
            "efforts repeated consistently: 1\n",
            "repeated consistently over: 1\n",
            "consistently over time.: 1\n",
            "over time. officials: 1\n",
            "time. officials announced: 1\n",
            "officials announced new: 1\n",
            "announced new policies: 1\n",
            "new policies to: 1\n",
            "policies to improve: 1\n",
            "to improve public: 1\n",
            "improve public transportation.: 1\n",
            "public transportation. every: 1\n",
            "transportation. every challenge: 1\n",
            "every challenge you: 1\n",
            "challenge you face: 1\n",
            "you face is: 1\n",
            "face is an: 1\n",
            "is an opportunity: 1\n",
            "an opportunity to: 1\n",
            "opportunity to grow.: 1\n"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "\n",
        "\n",
        "combined_text = f\"{D1content} {D2content} {D3content} {D4content} {D5content} {D6content} {D7content} {D8content} {D9content} {D10content}\"\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "Trigrams = []\n",
        "for i in range(len(words) - 2):\n",
        "    Trigrams.append((words[i], words[i+1], words[i+2]))\n",
        "\n",
        "Trigrams_counts = collections.Counter(Trigrams)\n",
        "\n",
        "print(\"\\nTrigrams Counts:\")\n",
        "for Trigrams, count in Trigrams_counts.most_common():\n",
        "    print(f\"{Trigrams[0]} {Trigrams[1]} {Trigrams[2]}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DItPCeDyWqk9"
      },
      "source": [
        "Next Word Prediction Using Bi-Gram Counts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKEfO4thWrga",
        "outputId": "2d6a5e4e-31c2-4820-9ced-a671b256bc12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  writing is  1.0\n",
            "Given sequence: 'I am', predicted next word: 'writing'\n",
            "Given sequence: 'I did my', predicted next word: 'No bigram found starting with 'my'.'\n",
            "probability of  am is  1.0\n",
            "Given sequence: 'professor I', predicted next word: 'am'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ],
      "source": [
        "def predict_next_word_bigram(word_sequence, bigram_counts, unigram_counts):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = bigram_count / last_word_unigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "sequence1 = \"I am\"\n",
        "next_word1 = predict_next_word_bigram(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_bigram(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"professor I\"\n",
        "next_word3 = predict_next_word_bigram(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zj0MBOtXH0D"
      },
      "source": [
        "Deployment of Bi-Gram Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbBt5JXyW-_5",
        "outputId": "c98003da-ede5-43d9-ccda-450000597dcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter texti am\n",
            "probability of  writing is  1.0\n",
            "Given sequence: 'i am', predicted next word: 'writing'\n"
          ]
        }
      ],
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvLC0nDLYdX0",
        "outputId": "ec8983ea-e60f-41f2-de40-978afa9458bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Given sequence: 'I am working', predicted next word: 'No trigram found starting with 'am working'.'\n",
            "Given sequence: 'I did my', predicted next word: 'No trigram found starting with 'did my'.'\n"
          ]
        }
      ],
      "source": [
        "def predict_next_word_trigram(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = trigram_count / last_two_words_bigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "sequence1 = \"I am working\"\n",
        "next_word1 = predict_next_word_trigram(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_trigram(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ve_d9zwhZeCL"
      },
      "source": [
        "Deployment of Tri-Gram Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiOZUzlfZdht",
        "outputId": "5a3e64dd-151f-46c9-ffad-8be8026d449d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enter textAre you coming \n",
            "probability of  with is  1.0\n",
            "Given sequence: 'Are you coming ', predicted next word: 'with'\n"
          ]
        }
      ],
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-pCXsYxa7-s"
      },
      "source": [
        "Next Word Prediction Using Bi-Gram Counts with Laplace Smoothening"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrsYfGgXa8Zd",
        "outputId": "318f5952-b152-4f3e-d06c-79f6a6bfa47d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "probability of writing is  0.024096385542168676\n",
            "Given sequence: 'I am', predicted next word: 'writing'\n",
            "Given sequence: 'I did my', predicted next word: 'No bigram found starting with 'my'.'\n",
            "probability of am is  0.024096385542168676\n",
            "Given sequence: 'professor I', predicted next word: 'am'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ],
      "source": [
        "def predict_next_word_bigram_Laplace(word_sequence, bigram_counts, unigram_counts):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+1) / (last_word_unigram_count+V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "sequence1 = \"I am\"\n",
        "next_word1 = predict_next_word_bigram_Laplace(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_bigram_Laplace(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"professor I\"\n",
        "next_word3 = predict_next_word_bigram_Laplace(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram_Laplace(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpz-HcfSbkYU"
      },
      "source": [
        "Deployment of Laplace Smoothening based Bi-Gram Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHLfz7YbbhgR",
        "outputId": "2e0e4153-8c6b-4a69-8396-9bad6561ef93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enter textis an\n",
            "probability of opportunity is  0.024096385542168676\n",
            "Given sequence: 'is an', predicted next word: 'opportunity'\n"
          ]
        }
      ],
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_Laplace(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2md7K_DFbzab"
      },
      "source": [
        "Next Word Prediction Using Tri-Gram Counts based on laplace smoothening"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uXwfIYGDb1aS",
        "outputId": "59ec61c5-a18f-495d-cf97-9f737d66b479"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Given sequence: 'I am working', predicted next word: 'No trigram found starting with 'am working'.'\n",
            "Given sequence: 'I did my', predicted next word: 'No trigram found starting with 'did my'.'\n"
          ]
        }
      ],
      "source": [
        "def predict_next_word_trigram_Laplace(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+1) / (last_two_words_bigram_count+V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "sequence1 = \"I am working\"\n",
        "next_word1 = predict_next_word_trigram_Laplace(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_trigram_Laplace(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Laplace Smoothening based Tri-Gram Model"
      ],
      "metadata": {
        "id": "s7Tvjdc8dhl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_Laplace(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nldxhZN4don6",
        "outputId": "a606c61d-e9df-4d19-ed4a-c2cd84f059ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textThe aroma of \n",
            "probability of  fresh is  0.024096385542168676\n",
            "Given sequence: 'The aroma of ', predicted next word: 'fresh'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Bi-Gram Counts with Add - K Smoothening"
      ],
      "metadata": {
        "id": "h9TBwgcJeAha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_next_word_bigram_K(word_sequence, bigram_counts, unigram_counts, K):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+K) / (last_word_unigram_count+K*V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "sequence1 = \"I am\"\n",
        "next_word1 = predict_next_word_bigram_K(sequence1, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_bigram_K(sequence2, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"professor I\"\n",
        "next_word3 = predict_next_word_bigram_K(sequence3, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram_K(sequence4, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "id": "Gn38N207ePuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20dc639b-f947-4823-d136-5851fbde4fe7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of writing is  0.03571428571428571\n",
            "Given sequence: 'I am', predicted next word: 'writing'\n",
            "Given sequence: 'I did my', predicted next word: 'No bigram found starting with 'my'.'\n",
            "probability of am is  0.03571428571428571\n",
            "Given sequence: 'professor I', predicted next word: 'am'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Add-K Smoothening based Bi-Gram Model"
      ],
      "metadata": {
        "id": "nXBLhYIDAHG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_K(ip_text, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2UpQs-4AH5H",
        "outputId": "b2a97c95-21ab-48e2-9c8a-73bfd52f38c4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter texti am\n",
            "probability of writing is  0.03571428571428571\n",
            "Given sequence: 'i am', predicted next word: 'writing'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Tri-Gram Counts with Add - K Smoothening"
      ],
      "metadata": {
        "id": "-Sx9Al2jA4C2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_K(word_sequence, Trigrams_counts, bigram_counts,K): #K=0.5-0.01\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+K) / (last_two_words_bigram_count+K*V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"I am working\"\n",
        "next_word1 = predict_next_word_trigram_K(sequence1, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_trigram_K(sequence2, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQ2OWRRqAXPd",
        "outputId": "70cc9af3-3fc6-457a-da26-97f2afa9ba6e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'I am working', predicted next word: 'No trigram found starting with 'am working'.'\n",
            "Given sequence: 'I did my', predicted next word: 'No trigram found starting with 'did my'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Add-K Smoothening based Tri-Gram Model\n"
      ],
      "metadata": {
        "id": "XhFJUkszBPbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_K(ip_text, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh2Bw6AFBQHk",
        "outputId": "4c7e5d86-0449-4178-93b7-ce6975dbafea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textRecycling daily helps\n",
            "probability of  protect is  0.03571428571428571\n",
            "Given sequence: 'Recycling daily helps', predicted next word: 'protect'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNP7BA7tGvivrP2jaBx6bk9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}